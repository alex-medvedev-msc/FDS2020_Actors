{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "from data_utils.loader import Loader\n",
    "from model.deconfounder import Deconfounder\n",
    "from pyro.optim import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/ohe_movies.csv\"\n",
    "loader = Loader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2544, 129]) torch.Size([637, 129]) torch.Size([2544]) torch.Size([637])\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = loader.get_train_test()\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MSE: 1.8751, mean baseline mse: 1.9978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "'''\n",
    "scaler = StandardScaler()\n",
    "y_train_t = scaler.fit_transform(y_train.numpy().reshape(-1, 1))\n",
    "y_test_t = scaler.transform(y_test.numpy().reshape(-1, 1))\n",
    "'''\n",
    "\n",
    "'''\n",
    "y_train_t = np.log1p(y_train.numpy())\n",
    "y_test_t = np.log1p(y_test.numpy())\n",
    "'''\n",
    "\n",
    "lr = LinearRegression()\n",
    "lr.fit(X_train.numpy(), y_train.numpy())\n",
    "y_pred = lr.predict(X_test.numpy())\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "\n",
    "y_mean = np.zeros(y_test.shape) + y_train.numpy().mean()\n",
    "mean_mse = mean_squared_error(y_test.numpy(), y_mean)\n",
    "print(f'Linear regression MSE: {mse:.4f}, mean baseline mse: {mean_mse:.4f}')\n",
    "\n",
    "#log_mse = mean_squared_error(np.log1p(y_test.numpy()), np.log1p(y_pred))\n",
    "#log_mean_mse = mean_squared_error(np.log1p(y_test.numpy()), np.log1p(y_mean))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear conf\n",
    "step1_opt = Adam({\"lr\": 0.0005})\n",
    "step2_opt = Adam({\"lr\": 0.005})\n",
    "# seed def = 3493204\n",
    "deconfounder = Deconfounder(step1_opt, step2_opt, \n",
    "                            seed=5323,\n",
    "                            step1_iters=4000, step2_iters=1500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Z marginal and W parameter marginal...\n",
      "[iteration 0001] loss: 376.1324\n",
      "[iteration 0101] loss: 359.4549\n",
      "[iteration 0201] loss: 338.7086\n",
      "[iteration 0301] loss: 328.9077\n",
      "[iteration 0401] loss: 314.5475\n",
      "[iteration 0501] loss: 302.1743\n",
      "[iteration 0601] loss: 287.8564\n",
      "[iteration 0701] loss: 277.7061\n",
      "[iteration 0801] loss: 266.3705\n",
      "[iteration 0901] loss: 257.6144\n",
      "[iteration 1001] loss: 247.6543\n",
      "[iteration 1101] loss: 227.7157\n",
      "[iteration 1201] loss: 213.3058\n",
      "[iteration 1301] loss: 191.6192\n",
      "[iteration 1401] loss: 158.5139\n",
      "[iteration 1501] loss: 129.1670\n",
      "[iteration 1601] loss: 95.9907\n",
      "[iteration 1701] loss: 71.5628\n",
      "[iteration 1801] loss: 53.1820\n",
      "[iteration 1901] loss: 41.1869\n",
      "[iteration 2001] loss: 35.7594\n",
      "[iteration 2101] loss: 29.6489\n",
      "[iteration 2201] loss: 27.7824\n",
      "[iteration 2301] loss: 24.2861\n",
      "[iteration 2401] loss: 22.9345\n",
      "[iteration 2501] loss: 20.7526\n",
      "[iteration 2601] loss: 20.8910\n",
      "[iteration 2701] loss: 20.3350\n",
      "[iteration 2801] loss: 20.0229\n",
      "[iteration 2901] loss: 19.6403\n",
      "[iteration 3001] loss: 19.1046\n",
      "[iteration 3101] loss: 18.6926\n",
      "[iteration 3201] loss: 18.5142\n",
      "[iteration 3301] loss: 18.6009\n",
      "[iteration 3401] loss: 18.0248\n",
      "[iteration 3501] loss: 18.0564\n",
      "[iteration 3601] loss: 17.9531\n",
      "[iteration 3701] loss: 17.4732\n",
      "[iteration 3801] loss: 17.9694\n",
      "[iteration 3901] loss: 17.5171\n",
      "Updating value of hypermeterqz_mean\n",
      "Updating value of hypermeterqz_stddv\n",
      "Updating value of hypermeterqw_mean\n",
      "Updating value of hypermeterqw_stddv\n",
      "Training Bayesian regression parameters...\n",
      "[iteration 0001] loss: 177.1177\n",
      "[iteration 0101] loss: 72.0064\n",
      "[iteration 0201] loss: 40.2455\n",
      "[iteration 0301] loss: 32.5561\n",
      "[iteration 0401] loss: 24.9716\n",
      "[iteration 0501] loss: 23.1213\n",
      "[iteration 0601] loss: 26.8465\n",
      "[iteration 0701] loss: 26.7774\n",
      "[iteration 0801] loss: 21.3431\n",
      "[iteration 0901] loss: 21.7208\n",
      "[iteration 1001] loss: 21.3831\n",
      "[iteration 1101] loss: 20.4974\n",
      "[iteration 1201] loss: 20.6767\n",
      "[iteration 1301] loss: 20.0037\n",
      "[iteration 1401] loss: 20.1810\n",
      "Updating value of hypermeter: w_loc\n",
      "Updating value of hypermeter: w_scale\n",
      "Updating value of hypermeter: b_loc\n",
      "Updating value of hypermeter: b_scale\n",
      "Updating value of hypermeter: sigma_loc\n",
      "Updating value of hypermeter: sigma_scale\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "step1_params, step2_params = deconfounder.train(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.571259097311846"
      ]
     },
     "execution_count": 279,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#y_train_pred = deconfounder.do_predict(X_train)\n",
    "\n",
    "y_test_pred, test_params = deconfounder.do_predict(X_test, num_samples=5000)\n",
    "mean_squared_error(y_test_pred, y_test.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.6083607922924124"
      ]
     },
     "execution_count": 281,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_cond_pred, test_params = deconfounder.cond_predict(X_test, num_samples=5000)\n",
    "mean_squared_error(y_cond_pred, y_test.numpy())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region top actors comp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.8182, 1.6285, 1.5604, 1.7617, 1.7346, 1.7701, 1.4960, 1.5053, 1.6079,\n",
       "        1.7688, 1.4529, 1.3123, 1.5816, 1.4644, 1.3396, 1.6510, 1.6191, 1.6058,\n",
       "        1.6220, 1.5604, 1.5907, 1.5962, 1.6871, 1.7202, 1.3986, 1.6934, 1.4617,\n",
       "        1.3779, 1.4652, 1.1988, 1.1442, 1.6474, 1.4420, 1.6459, 1.6691, 1.4636,\n",
       "        1.4873, 1.6070, 1.7141, 1.6042, 1.7807, 1.3410, 1.4711, 1.6033, 1.4159,\n",
       "        1.6093, 1.6258, 1.6035, 1.7553, 1.8049, 1.5283, 1.7332, 1.7465, 1.4748,\n",
       "        1.5671, 1.7713, 1.5871, 1.5560, 1.4548, 1.4841, 1.5508, 1.6885, 1.6681,\n",
       "        1.4200, 1.6070, 1.5168, 1.4997, 1.6552, 1.5184, 1.6859, 1.6013, 1.5187,\n",
       "        1.7189, 1.3657, 1.4830, 1.4036, 1.4509, 1.5208, 1.5160, 1.4138, 1.5976,\n",
       "        1.6348, 1.5446, 1.3147, 1.5126, 1.6687, 1.6992, 1.3947, 1.6287, 1.5731,\n",
       "        1.5393, 1.6992, 1.4589, 1.4735, 1.5179, 1.6099, 1.3243, 1.6860, 1.5757,\n",
       "        1.8483, 1.6292, 1.4032, 1.5979, 1.4567, 1.6150, 1.8282, 1.6312, 1.6876,\n",
       "        1.7191, 1.5725, 1.7013, 1.5100, 1.6578, 1.4169, 1.6246, 1.5739, 1.7021,\n",
       "        1.3044, 1.2167, 1.5842, 1.8526, 1.8471, 1.5804, 1.6489, 1.3638, 1.4838,\n",
       "        1.9661, 1.4931, 1.3586], grad_fn=<SliceBackward>)"
      ]
     },
     "execution_count": 311,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = deconfounder.step2_params\n",
    "actor_weights = params['weight_mean0'][:-50]\n",
    "actor_weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Adam Sandler', 'Alec Baldwin', 'Amy Adams', 'Angelina Jolie',\n",
       "       'Anna Faris', 'Anne Hathaway', 'Anthony Hopkins', 'Anthony Mackie',\n",
       "       'Antonio Banderas', 'Arnold Schwarzenegger',\n",
       "       ...\n",
       "       'Sylvester Stallone', 'Tom Cruise', 'Tom Hanks', 'Tom Wilkinson',\n",
       "       'Tommy Lee Jones', 'Vince Vaughn', 'Will Ferrell', 'Will Smith',\n",
       "       'Willem Dafoe', 'Woody Harrelson'],\n",
       "      dtype='object', length=129)"
      ]
     },
     "execution_count": 290,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors = loader.data_X.columns[:-1]\n",
    "actors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam Sandler</th>\n",
       "      <td>1.818185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alec Baldwin</th>\n",
       "      <td>1.628481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy Adams</th>\n",
       "      <td>1.560416</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angelina Jolie</th>\n",
       "      <td>1.761667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Faris</th>\n",
       "      <td>1.734576</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vince Vaughn</th>\n",
       "      <td>1.363815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will Ferrell</th>\n",
       "      <td>1.483769</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will Smith</th>\n",
       "      <td>1.966060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willem Dafoe</th>\n",
       "      <td>1.493105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woody Harrelson</th>\n",
       "      <td>1.358649</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   weight\n",
       "Adam Sandler     1.818185\n",
       "Alec Baldwin     1.628481\n",
       "Amy Adams        1.560416\n",
       "Angelina Jolie   1.761667\n",
       "Anna Faris       1.734576\n",
       "...                   ...\n",
       "Vince Vaughn     1.363815\n",
       "Will Ferrell     1.483769\n",
       "Will Smith       1.966060\n",
       "Willem Dafoe     1.493105\n",
       "Woody Harrelson  1.358649\n",
       "\n",
       "[129 rows x 1 columns]"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "actors_frame = pd.DataFrame(data=actor_weights.detach().numpy(), \n",
    "                            index=actors, \n",
    "                            columns=['weight'])\n",
    "\n",
    "actors_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Will Smith</th>\n",
       "      <td>1.966060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom Cruise</th>\n",
       "      <td>1.852589</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ralph Fiennes</th>\n",
       "      <td>1.848259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom Hanks</th>\n",
       "      <td>1.847136</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Robin Williams</th>\n",
       "      <td>1.828198</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Kingsley</th>\n",
       "      <td>1.312298</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Steve Zahn</th>\n",
       "      <td>1.304400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Susan Sarandon</th>\n",
       "      <td>1.216737</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Christopher Walken</th>\n",
       "      <td>1.198792</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colin Farrell</th>\n",
       "      <td>1.144204</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      weight\n",
       "Will Smith          1.966060\n",
       "Tom Cruise          1.852589\n",
       "Ralph Fiennes       1.848259\n",
       "Tom Hanks           1.847136\n",
       "Robin Williams      1.828198\n",
       "...                      ...\n",
       "Ben Kingsley        1.312298\n",
       "Steve Zahn          1.304400\n",
       "Susan Sarandon      1.216737\n",
       "Christopher Walken  1.198792\n",
       "Colin Farrell       1.144204\n",
       "\n",
       "[129 rows x 1 columns]"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_frame.sort_values(by='weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region Linear regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Uniform, Delta\n",
    "from pyro.infer import SVI, Trace_ELBO\n",
    "from pyro.optim import Adam\n",
    "from pyro.distributions.util import logsumexp\n",
    "from pyro.infer import EmpiricalMarginal, TracePredictive\n",
    "from pyro.infer.mcmc import MCMC, NUTS\n",
    "import pyro.optim as optim\n",
    "import pyro.poutine as poutine\n",
    "\n",
    "\n",
    "# Lets define a new regression model\n",
    "class RegressionModel(nn.Module):\n",
    "    \n",
    "    def __init__(self, p):\n",
    "        super(RegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(p, 1)\n",
    "#         self.factor = nn.Parameter(torch.tensor(1.0))\n",
    "        \n",
    "    def forward(self, x):\n",
    "\n",
    "        return self.linear(x).reshape(X_train.shape[0])\n",
    "    \n",
    "    \n",
    "p = 129  # number of actors\n",
    "regression_model = RegressionModel(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(x_data, y_data):\n",
    "    \n",
    "    dims = x_data.shape[1]\n",
    "    # weight, bias, and factor priors\n",
    "    w_prior = Normal(torch.zeros(1, dims), torch.ones(1, dims)).to_event(1)\n",
    "    b_prior = Normal(torch.tensor([[8.]]), torch.tensor([[1000.]])).to_event(1)\n",
    "#     f_prior = Normal(0., 1.)\n",
    "\n",
    "    priors = {'linear.weight': w_prior, 'linear.bias': b_prior}\n",
    "    scale = pyro.sample(\"linear.sigma\", Uniform(0., 10.))\n",
    "    \n",
    "    lifted_module = pyro.random_module(\"module\", regression_model, priors)\n",
    "    lifted_reg_model = lifted_module()\n",
    "#     with pyro.plate(\"map\", len(x_data)):\n",
    "    with pyro.plate(\"map\", len(x_data)):\n",
    "        prediction_mean = lifted_reg_model(x_data)\n",
    "        pyro.sample(\"obs\", Normal(prediction_mean, scale))\n",
    "\n",
    "        return prediction_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from pyro.infer.autoguide import AutoDiagonalNormal\n",
    "# initialize the autodiagonal with init_to_feasible instead of init_to_median\n",
    "from pyro.infer.autoguide import init_to_feasible"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ag3r/anaconda3/envs/causality/lib/python3.7/site-packages/pyro/infer/svi.py:53: FutureWarning: The `num_samples` argument to SVI is deprecated and will be removed in a future release. Use `pyro.infer.Predictive` class to draw samples from the posterior.\n",
      "  'samples from the posterior.', FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "optim = Adam({\"lr\": 0.03})\n",
    "cond_model = pyro.condition(model, data = {\"obs\" : y_train.reshape(y_train.shape[0])})\n",
    "guide = AutoDiagonalNormal(cond_model, init_loc_fn = init_to_feasible)\n",
    "svi = SVI(cond_model, guide, optim, loss=Trace_ELBO(), num_samples=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0001] loss: 9.1608\n",
      "[iteration 0101] loss: 4.6323\n",
      "[iteration 0201] loss: 4.1594\n",
      "[iteration 0301] loss: 3.8915\n",
      "[iteration 0401] loss: 3.6893\n",
      "[iteration 0501] loss: 3.5365\n",
      "[iteration 0601] loss: 3.4035\n",
      "[iteration 0701] loss: 3.2635\n",
      "[iteration 0801] loss: 3.0610\n",
      "[iteration 0901] loss: 2.3928\n"
     ]
    }
   ],
   "source": [
    "pyro.set_rng_seed(101)\n",
    "num_iterations = 1000\n",
    "def train():\n",
    "    pyro.clear_param_store()\n",
    "    for j in range(num_iterations):\n",
    "        loss = svi.step(X_train, y_train.reshape(1, y_train.shape[0]))\n",
    "        if j % 100 == 0:\n",
    "            print(\"[iteration %04d] loss: %.4f\" % (j + 1, loss/len(X_train)))\n",
    "            \n",
    "train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AutoDiagonalNormal.loc Parameter containing:\n",
      "tensor([-1.8485e+00,  8.5459e-01,  5.0851e-01,  3.1549e-01,  5.6810e-01,\n",
      "         8.1622e-01,  9.2847e-01,  7.6569e-02, -3.8580e-02,  3.8488e-01,\n",
      "         1.1272e+00, -9.9346e-02, -6.0358e-02,  3.4970e-01, -7.9366e-02,\n",
      "        -1.6901e-01,  5.2637e-01,  5.3432e-01,  5.3909e-01,  2.9002e-01,\n",
      "         2.0374e-01,  4.1247e-01,  5.1824e-01,  5.0375e-01,  6.5129e-01,\n",
      "        -1.6786e-01,  5.9988e-01, -3.8645e-02, -1.1462e-01,  4.2468e-01,\n",
      "        -4.5529e-01, -4.4450e-01,  6.8353e-01, -5.6986e-02,  5.2011e-01,\n",
      "         7.4689e-01, -1.6481e-02,  1.5911e-01,  2.2712e-01,  7.6906e-01,\n",
      "         3.3581e-01,  7.7821e-01, -2.8460e-01,  2.8065e-01,  2.5643e-01,\n",
      "         4.1029e-02,  5.4705e-01,  6.6607e-01,  4.5912e-01,  5.3267e-01,\n",
      "         7.7372e-01,  2.9395e-01,  6.4536e-01,  7.1141e-01,  5.3548e-02,\n",
      "         3.0119e-01,  6.7707e-01,  3.2084e-01,  2.8665e-01, -7.4225e-02,\n",
      "        -5.0868e-02,  4.5973e-01,  7.7304e-01,  6.7649e-01,  1.4523e-01,\n",
      "         5.7528e-01,  2.5720e-01,  2.6884e-01,  6.6556e-01,  2.5716e-02,\n",
      "         8.4592e-01,  1.7390e-01,  2.4938e-01,  6.6208e-01, -1.4699e-01,\n",
      "        -2.0855e-02,  3.5169e-03,  1.2917e-01,  4.0151e-01,  1.5043e-01,\n",
      "         1.1874e-01,  2.8382e-01,  4.3415e-01,  2.1397e-01, -5.3048e-01,\n",
      "         2.8999e-01,  7.5264e-01,  6.3747e-01,  1.4607e-02,  5.4733e-01,\n",
      "         3.1973e-01,  3.9138e-01,  9.0988e-01,  1.7284e-01,  2.7225e-01,\n",
      "         3.7241e-01,  5.0822e-01, -5.6483e-02,  8.1409e-01,  4.9071e-01,\n",
      "         1.1548e+00,  3.7210e-01,  6.8846e-02,  4.6133e-01, -1.4335e-01,\n",
      "         3.2681e-01,  1.2302e+00,  3.8354e-01,  6.4690e-01,  8.4029e-01,\n",
      "         6.4863e-01,  4.8213e-01,  2.4585e-01,  6.2897e-01,  7.7614e-02,\n",
      "         4.8612e-01,  2.0338e-01,  7.5182e-01, -1.0970e-02, -4.2705e-01,\n",
      "         5.0485e-01,  1.0827e+00,  9.9761e-01,  2.5652e-01,  5.8841e-01,\n",
      "        -3.8659e-01,  1.3976e-01,  1.3540e+00,  2.1689e-01, -9.1871e-02,\n",
      "         1.7359e+01], requires_grad=True) torch.Size([131])\n",
      "AutoDiagonalNormal.scale tensor([0.0795, 0.2643, 0.3451, 0.3454, 0.3663, 0.3379, 0.3775, 0.3299, 0.4169,\n",
      "        0.3331, 0.2787, 0.3523, 0.2773, 0.2897, 0.4517, 0.2621, 0.2736, 0.2820,\n",
      "        0.3393, 0.3184, 0.2704, 0.2966, 0.1938, 0.2359, 0.2882, 0.3748, 0.2932,\n",
      "        0.3245, 0.3197, 0.2943, 0.3722, 0.3035, 0.3662, 0.3194, 0.2838, 0.3659,\n",
      "        0.3190, 0.3090, 0.3455, 0.2922, 0.2729, 0.3077, 0.3103, 0.3205, 0.3517,\n",
      "        0.3580, 0.3127, 0.3452, 0.4215, 0.2993, 0.3066, 0.3233, 0.3657, 0.2656,\n",
      "        0.2379, 0.3347, 0.3302, 0.2919, 0.3406, 0.3260, 0.2788, 0.3713, 0.3333,\n",
      "        0.2952, 0.4174, 0.3197, 0.3292, 0.3463, 0.2935, 0.3204, 0.2670, 0.3704,\n",
      "        0.3095, 0.2688, 0.2543, 0.3045, 0.4109, 0.3558, 0.3663, 0.3917, 0.3641,\n",
      "        0.4437, 0.3941, 0.2390, 0.3218, 0.2943, 0.2877, 0.2636, 0.2908, 0.3179,\n",
      "        0.2573, 0.2464, 0.2959, 0.3158, 0.3519, 0.2789, 0.3317, 0.2513, 0.3020,\n",
      "        0.3034, 0.2804, 0.3038, 0.2307, 0.3795, 0.3750, 0.3893, 0.2886, 0.2975,\n",
      "        0.3347, 0.2548, 0.3059, 0.3569, 0.3609, 0.2454, 0.3662, 0.2710, 0.2923,\n",
      "        0.3050, 0.3166, 0.3117, 0.3183, 0.2693, 0.3238, 0.3479, 0.3359, 0.3265,\n",
      "        0.2669, 0.3319, 0.4116, 0.3141, 0.0606], grad_fn=<AddBackward0>) torch.Size([131])\n"
     ]
    }
   ],
   "source": [
    "for name, value in pyro.get_param_store().items():\n",
    "    print(name, pyro.param(name), pyro.param(name).shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {},
   "outputs": [],
   "source": [
    "linreg_params = {}\n",
    "for name, value in pyro.get_param_store().items():\n",
    "    linreg_params[name] = pyro.param(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([129])"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linreg_mean = linreg_params['AutoDiagonalNormal.loc'][:-2]\n",
    "linreg_mean.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Adam Sandler</th>\n",
       "      <td>-1.848469</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Alec Baldwin</th>\n",
       "      <td>0.854593</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Amy Adams</th>\n",
       "      <td>0.508507</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Angelina Jolie</th>\n",
       "      <td>0.315485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Anna Faris</th>\n",
       "      <td>0.568104</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Vince Vaughn</th>\n",
       "      <td>0.588407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will Ferrell</th>\n",
       "      <td>-0.386592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Will Smith</th>\n",
       "      <td>0.139761</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Willem Dafoe</th>\n",
       "      <td>1.353994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Woody Harrelson</th>\n",
       "      <td>0.216891</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                   weight\n",
       "Adam Sandler    -1.848469\n",
       "Alec Baldwin     0.854593\n",
       "Amy Adams        0.508507\n",
       "Angelina Jolie   0.315485\n",
       "Anna Faris       0.568104\n",
       "...                   ...\n",
       "Vince Vaughn     0.588407\n",
       "Will Ferrell    -0.386592\n",
       "Will Smith       0.139761\n",
       "Willem Dafoe     1.353994\n",
       "Woody Harrelson  0.216891\n",
       "\n",
       "[129 rows x 1 columns]"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "\n",
    "actors_frame = pd.DataFrame(data=linreg_mean.detach().numpy(), \n",
    "                            index=actors, \n",
    "                            columns=['weight'])\n",
    "\n",
    "actors_frame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>weight</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Willem Dafoe</th>\n",
       "      <td>1.353994</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Russell Crowe</th>\n",
       "      <td>1.230186</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Richard Jenkins</th>\n",
       "      <td>1.154806</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Ben Affleck</th>\n",
       "      <td>1.127194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tom Hanks</th>\n",
       "      <td>1.082718</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Sylvester Stallone</th>\n",
       "      <td>-0.427047</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Danny Glover</th>\n",
       "      <td>-0.444503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Colin Farrell</th>\n",
       "      <td>-0.455286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mark Ruffalo</th>\n",
       "      <td>-0.530481</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Adam Sandler</th>\n",
       "      <td>-1.848469</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>129 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                      weight\n",
       "Willem Dafoe        1.353994\n",
       "Russell Crowe       1.230186\n",
       "Richard Jenkins     1.154806\n",
       "Ben Affleck         1.127194\n",
       "Tom Hanks           1.082718\n",
       "...                      ...\n",
       "Sylvester Stallone -0.427047\n",
       "Danny Glover       -0.444503\n",
       "Colin Farrell      -0.455286\n",
       "Mark Ruffalo       -0.530481\n",
       "Adam Sandler       -1.848469\n",
       "\n",
       "[129 rows x 1 columns]"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actors_frame.sort_values(by='weight', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Region new approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 321,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3181, 129])\n"
     ]
    }
   ],
   "source": [
    "# linear conf\n",
    "step1_opt = Adam({\"lr\": 0.0005})\n",
    "step2_opt = Adam({\"lr\": 0.005})\n",
    "# seed def = 3493204\n",
    "latent_dim = 50\n",
    "deconfounder = Deconfounder(step1_opt, step2_opt, \n",
    "                            seed=5323, latent_dim=latent_dim,\n",
    "                            step1_iters=4000, step2_iters=1500)\n",
    "\n",
    "X_total = torch.cat([X_train, X_test], dim=0)\n",
    "num_datapoints, data_dim = X_total.shape\n",
    "\n",
    "print(X_total.shape)\n",
    "\n",
    "params0 = {\n",
    "            'z_mean0': torch.zeros([num_datapoints, latent_dim]),\n",
    "            'z_std0' : torch.ones([num_datapoints, latent_dim]),\n",
    "            'w_mean0' : torch.zeros([latent_dim, data_dim]),\n",
    "            'w_std0' : torch.ones([latent_dim, data_dim]),\n",
    "            'weight_mean0': torch.zeros(data_dim + latent_dim),\n",
    "            'weight_std0': torch.ones(data_dim + latent_dim),\n",
    "            'bias_mean0': torch.tensor(0.),\n",
    "            'bias_std0': torch.tensor(1.),\n",
    "            'sigma_mean0' : torch.tensor(1.),\n",
    "            'sigma_std0' : torch.tensor(0.05)\n",
    "} # These are our priors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Z marginal and W parameter marginal...\n",
      "[iteration 0001] loss: 378.0973\n",
      "[iteration 0101] loss: 357.2834\n",
      "[iteration 0201] loss: 336.0044\n",
      "[iteration 0301] loss: 325.4726\n",
      "[iteration 0401] loss: 312.4409\n",
      "[iteration 0501] loss: 298.0004\n",
      "[iteration 0601] loss: 286.4980\n",
      "[iteration 0701] loss: 277.2229\n",
      "[iteration 0801] loss: 265.7027\n",
      "[iteration 0901] loss: 250.5860\n",
      "[iteration 1001] loss: 242.4821\n",
      "[iteration 1101] loss: 230.3570\n",
      "[iteration 1201] loss: 204.3405\n",
      "[iteration 1301] loss: 183.0812\n",
      "[iteration 1401] loss: 154.9663\n",
      "[iteration 1501] loss: 119.6357\n",
      "[iteration 1601] loss: 84.5333\n",
      "[iteration 1701] loss: 64.3600\n",
      "[iteration 1801] loss: 48.5605\n",
      "[iteration 1901] loss: 37.8786\n",
      "[iteration 2001] loss: 33.3633\n",
      "[iteration 2101] loss: 26.3783\n",
      "[iteration 2201] loss: 26.2111\n",
      "[iteration 2301] loss: 25.5467\n",
      "[iteration 2401] loss: 22.5107\n",
      "[iteration 2501] loss: 21.8003\n",
      "[iteration 2601] loss: 20.4285\n",
      "[iteration 2701] loss: 20.5855\n",
      "[iteration 2801] loss: 19.6072\n",
      "[iteration 2901] loss: 18.8053\n",
      "[iteration 3001] loss: 19.4306\n",
      "[iteration 3101] loss: 18.8612\n",
      "[iteration 3201] loss: 19.1488\n",
      "[iteration 3301] loss: 18.4284\n",
      "[iteration 3401] loss: 18.3390\n",
      "[iteration 3501] loss: 18.2228\n",
      "[iteration 3601] loss: 17.6324\n",
      "[iteration 3701] loss: 17.6869\n",
      "[iteration 3801] loss: 17.8981\n",
      "[iteration 3901] loss: 17.3885\n",
      "Updating value of hypermeterqz_mean\n",
      "Updating value of hypermeterqz_stddv\n",
      "Updating value of hypermeterqw_mean\n",
      "Updating value of hypermeterqw_stddv\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'z_mean0': tensor([[ 0.4495,  0.6784,  0.1211,  ..., -0.2132,  0.1319,  0.2959],\n",
       "         [ 0.4225,  0.6337,  0.0989,  ..., -0.2060,  0.0981,  0.2357],\n",
       "         [ 0.3784,  0.5883,  0.1114,  ..., -0.1745,  0.0581,  0.1897],\n",
       "         ...,\n",
       "         [ 0.4575,  0.6761,  0.1212,  ..., -0.2065,  0.0946,  0.2860],\n",
       "         [ 0.5145,  0.7474,  0.1361,  ..., -0.2666,  0.1270,  0.3292],\n",
       "         [ 0.5670,  0.7817,  0.1737,  ..., -0.3118,  0.1443,  0.3783]],\n",
       "        requires_grad=True),\n",
       " 'z_std0': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " 'w_mean0': tensor([[-0.5477, -0.5321, -0.5649,  ..., -0.5343, -0.5264, -0.5762],\n",
       "         [-0.8016, -0.7772, -0.7875,  ..., -0.7842, -0.7974, -0.7965],\n",
       "         [-0.1655, -0.1453, -0.1701,  ..., -0.1355, -0.1476, -0.1508],\n",
       "         ...,\n",
       "         [ 0.2842,  0.2558,  0.2885,  ...,  0.2687,  0.2776,  0.2966],\n",
       "         [-0.1205, -0.1404, -0.1450,  ..., -0.1451, -0.1182, -0.1412],\n",
       "         [-0.3440, -0.3519, -0.3572,  ..., -0.3637, -0.3446, -0.3559]],\n",
       "        requires_grad=True),\n",
       " 'w_std0': tensor([[1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         ...,\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.],\n",
       "         [1., 1., 1.,  ..., 1., 1., 1.]]),\n",
       " 'weight_mean0': tensor([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "         0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.]),\n",
       " 'weight_std0': tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
       "         1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.]),\n",
       " 'bias_mean0': tensor(0.),\n",
       " 'bias_std0': tensor(1.),\n",
       " 'sigma_mean0': tensor(1.),\n",
       " 'sigma_std0': tensor(0.0500),\n",
       " 'qz_mean': tensor([[ 0.4495,  0.6784,  0.1211,  ..., -0.2132,  0.1319,  0.2959],\n",
       "         [ 0.4225,  0.6337,  0.0989,  ..., -0.2060,  0.0981,  0.2357],\n",
       "         [ 0.3784,  0.5883,  0.1114,  ..., -0.1745,  0.0581,  0.1897],\n",
       "         ...,\n",
       "         [ 0.4575,  0.6761,  0.1212,  ..., -0.2065,  0.0946,  0.2860],\n",
       "         [ 0.5145,  0.7474,  0.1361,  ..., -0.2666,  0.1270,  0.3292],\n",
       "         [ 0.5670,  0.7817,  0.1737,  ..., -0.3118,  0.1443,  0.3783]]),\n",
       " 'qz_stddv': tensor([[0.7233, 0.7053, 0.7313,  ..., 0.7375, 0.7404, 0.7404],\n",
       "         [0.6978, 0.7002, 0.7345,  ..., 0.7151, 0.7277, 0.7193],\n",
       "         [0.6876, 0.6493, 0.7009,  ..., 0.7073, 0.7303, 0.6968],\n",
       "         ...,\n",
       "         [0.7166, 0.6930, 0.7483,  ..., 0.7437, 0.7408, 0.7240],\n",
       "         [0.7352, 0.6984, 0.7503,  ..., 0.7352, 0.7565, 0.7479],\n",
       "         [0.7420, 0.7276, 0.7620,  ..., 0.7626, 0.7482, 0.7570]]),\n",
       " 'qw_mean': tensor([[-0.5477, -0.5321, -0.5649,  ..., -0.5343, -0.5264, -0.5762],\n",
       "         [-0.8016, -0.7772, -0.7875,  ..., -0.7842, -0.7974, -0.7965],\n",
       "         [-0.1655, -0.1453, -0.1701,  ..., -0.1355, -0.1476, -0.1508],\n",
       "         ...,\n",
       "         [ 0.2842,  0.2558,  0.2885,  ...,  0.2687,  0.2776,  0.2966],\n",
       "         [-0.1205, -0.1404, -0.1450,  ..., -0.1451, -0.1182, -0.1412],\n",
       "         [-0.3440, -0.3519, -0.3572,  ..., -0.3637, -0.3446, -0.3559]]),\n",
       " 'qw_stddv': tensor([[0.5960, 0.5936, 0.5966,  ..., 0.6048, 0.5945, 0.6020],\n",
       "         [0.6007, 0.5939, 0.6007,  ..., 0.6064, 0.5932, 0.5982],\n",
       "         [0.6066, 0.6050, 0.6027,  ..., 0.6177, 0.6031, 0.5886],\n",
       "         ...,\n",
       "         [0.5979, 0.6100, 0.6017,  ..., 0.5962, 0.6059, 0.5778],\n",
       "         [0.6011, 0.5974, 0.6086,  ..., 0.5886, 0.5852, 0.6001],\n",
       "         [0.6004, 0.5897, 0.5841,  ..., 0.5882, 0.6007, 0.5875]])}"
      ]
     },
     "execution_count": 322,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1_params = deconfounder.step1_train(X_total, params0)\n",
    "step1_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2544, 50]), torch.Size([637, 50]))"
      ]
     },
     "execution_count": 325,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_train = step1_params['qz_mean'][:X_train.shape[0], :]\n",
    "Z_test = step1_params['qz_mean'][X_train.shape[0]:, :]\n",
    "Z_train.shape, Z_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([2544, 179]), torch.Size([637, 179]))"
      ]
     },
     "execution_count": 326,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reg_train = torch.cat([X_train, Z_train], dim=1)\n",
    "reg_test = torch.cat([X_test, Z_test], dim=1)\n",
    "reg_train.shape, reg_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MSE: 1.9235, mean baseline mse: 1.9978\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(reg_train.numpy(), y_train.numpy())\n",
    "y_pred = lr.predict(reg_test.numpy())\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "\n",
    "y_mean = np.zeros(y_test.shape) + y_train.numpy().mean()\n",
    "mean_mse = mean_squared_error(y_test.numpy(), y_mean)\n",
    "print(f'Linear regression MSE: {mse:.4f}, mean baseline mse: {mean_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MSE: 1.8751, mean baseline mse: 1.9978\n"
     ]
    }
   ],
   "source": [
    "lr = LinearRegression()\n",
    "lr.fit(X_train.numpy(), y_train.numpy())\n",
    "y_pred = lr.predict(X_test.numpy())\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "\n",
    "y_mean = np.zeros(y_test.shape) + y_train.numpy().mean()\n",
    "mean_mse = mean_squared_error(y_test.numpy(), y_mean)\n",
    "print(f'Linear regression MSE: {mse:.4f}, mean baseline mse: {mean_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MSE: 1.8234, mean baseline mse: 1.9978\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[2.111947 , 2.0980647, 2.2082143, 2.0721154, 2.107735 ],\n",
       "       [2.0968065, 2.0808842, 2.2082143, 2.0563896, 2.0934694],\n",
       "       [2.0831962, 2.065179 , 2.1895626, 2.042099 , 2.0760074],\n",
       "       [2.0709925, 2.0508204, 2.170254 , 2.0291107, 2.0600781],\n",
       "       [2.0602067, 2.0376918, 2.1527214, 2.0172405, 2.0454829],\n",
       "       [2.0505438, 2.0256557, 2.1367035, 2.0064347, 2.0321448],\n",
       "       [2.041898 , 2.0146406, 2.1220224, 1.9966362, 2.0199797],\n",
       "       [2.03406  , 2.0044613, 2.1084933, 1.9877579, 2.0088859],\n",
       "       [2.0270085, 1.9951521, 2.0960557, 1.9797167, 1.9987671],\n",
       "       [2.0207174, 1.9866352, 2.0846634, 1.9724336, 1.9895356],\n",
       "       [2.0151143, 1.9788384, 2.0742533, 1.9658401, 1.9811186],\n",
       "       [2.0101302, 1.9717011, 2.064778 , 1.9598749, 1.9734374],\n",
       "       [2.005279 , 1.9651674, 2.0560946, 1.9544768, 1.9664304],\n",
       "       [2.0008461, 1.9591838, 2.048132 , 1.9495976, 1.9600387],\n",
       "       [1.9969127, 1.9535763, 2.040831 , 1.9451866, 1.9542081],\n",
       "       [1.9934305, 1.9483068, 2.034135 , 1.9409744, 1.9488863],\n",
       "       [1.9903562, 1.943477 , 2.027993 , 1.9369673, 1.944032 ],\n",
       "       [1.9876463, 1.939046 , 2.0223525, 1.9333446, 1.9396019],\n",
       "       [1.9852662, 1.9349798, 2.0171745, 1.9301924, 1.935558 ],\n",
       "       [1.9831828, 1.9312494, 2.012422 , 1.9275246, 1.9313289],\n",
       "       [1.9813658, 1.9278245, 2.0079987, 1.9252641, 1.9273928],\n",
       "       [1.9798208, 1.9245082, 2.0037916, 1.9232459, 1.9236392],\n",
       "       [1.9784548, 1.9211334, 1.9999179, 1.9215328, 1.9201236],\n",
       "       [1.9769613, 1.9180431, 1.9963487, 1.9200922, 1.9168977],\n",
       "       [1.9748272, 1.9152137, 1.9931318, 1.9188901, 1.9139344],\n",
       "       [1.9726833, 1.9123424, 1.990252 , 1.9179301, 1.9112123],\n",
       "       [1.970813 , 1.909623 , 1.9875731, 1.916913 , 1.9082521],\n",
       "       [1.9692   , 1.9069953, 1.984782 , 1.9160906, 1.9053255],\n",
       "       [1.9678142, 1.9043856, 1.9807382, 1.9154919, 1.9013889],\n",
       "       [1.9666297, 1.9017103, 1.9763789, 1.9155718, 1.8974133],\n",
       "       [1.9654125, 1.8992534, 1.9724197, 1.9156406, 1.8939594],\n",
       "       [1.9640764, 1.8969892, 1.9685308, 1.9158684, 1.8909761],\n",
       "       [1.9622539, 1.8948716, 1.9642745, 1.9160973, 1.8882158],\n",
       "       [1.9605415, 1.8923337, 1.9609145, 1.9158338, 1.884939 ],\n",
       "       [1.9591161, 1.8896302, 1.9577448, 1.9147291, 1.8816173],\n",
       "       [1.9577603, 1.8870884, 1.9545963, 1.9136547, 1.8782022],\n",
       "       [1.9566147, 1.8835762, 1.9517894, 1.9128542, 1.8750465],\n",
       "       [1.955557 , 1.8799363, 1.9491489, 1.9126666, 1.8726567],\n",
       "       [1.9551121, 1.8758316, 1.9466585, 1.9118152, 1.8705829],\n",
       "       [1.954819 , 1.8714339, 1.9438196, 1.9107795, 1.8686062],\n",
       "       [1.9545239, 1.867358 , 1.9412582, 1.909849 , 1.8667456],\n",
       "       [1.9541171, 1.8633755, 1.9394133, 1.9084401, 1.8646275],\n",
       "       [1.9541094, 1.8600699, 1.9380181, 1.9073462, 1.8627925],\n",
       "       [1.9542029, 1.8573864, 1.9369642, 1.906747 , 1.8608917],\n",
       "       [1.9543765, 1.854526 , 1.936235 , 1.9064196, 1.8593175],\n",
       "       [1.9548037, 1.8519194, 1.9357183, 1.9063697, 1.8576454],\n",
       "       [1.9555311, 1.8494871, 1.9351326, 1.9067814, 1.8562728],\n",
       "       [1.9565935, 1.8471465, 1.9346405, 1.9079486, 1.8553058],\n",
       "       [1.9578617, 1.845071 , 1.9343872, 1.9092684, 1.8547981],\n",
       "       [1.9592313, 1.843405 , 1.9343439, 1.910677 , 1.8548546],\n",
       "       [1.960279 , 1.8416013, 1.9345207, 1.912524 , 1.8551621],\n",
       "       [1.9614964, 1.839213 , 1.9347857, 1.9144379, 1.8553283],\n",
       "       [1.9625714, 1.8370124, 1.9351362, 1.9165002, 1.8558487],\n",
       "       [1.9638383, 1.8350447, 1.936063 , 1.9186313, 1.8563738],\n",
       "       [1.9653171, 1.8333534, 1.9373014, 1.920794 , 1.856884 ],\n",
       "       [1.9669803, 1.8320314, 1.9387779, 1.9230802, 1.857423 ],\n",
       "       [1.9688685, 1.8310126, 1.9405165, 1.9254751, 1.8576138],\n",
       "       [1.9706469, 1.8301294, 1.9424529, 1.9278172, 1.8577017],\n",
       "       [1.9721452, 1.8293964, 1.9449832, 1.9300976, 1.8578144],\n",
       "       [1.9736602, 1.8291163, 1.9475446, 1.9324217, 1.8580847],\n",
       "       [1.9752989, 1.8291135, 1.9500673, 1.9347521, 1.8585767],\n",
       "       [1.9770639, 1.8293099, 1.9524003, 1.937201 , 1.8588907],\n",
       "       [1.978935 , 1.8296484, 1.9544519, 1.9398805, 1.8588881],\n",
       "       [1.980925 , 1.8300133, 1.9565487, 1.9425849, 1.8588449],\n",
       "       [1.9830265, 1.8301003, 1.9586165, 1.9450908, 1.8590838],\n",
       "       [1.9851353, 1.83018  , 1.9606166, 1.9477897, 1.8593677],\n",
       "       [1.9873205, 1.8304951, 1.9629049, 1.9504762, 1.8596479],\n",
       "       [1.9895139, 1.8308666, 1.965172 , 1.9531525, 1.8599967],\n",
       "       [1.9918991, 1.8312134, 1.9674097, 1.9556597, 1.8605018],\n",
       "       [1.9944474, 1.8315573, 1.9698087, 1.9581378, 1.8610587],\n",
       "       [1.9971489, 1.8320377, 1.9721905, 1.9606175, 1.8615395],\n",
       "       [1.9999729, 1.8325723, 1.9746454, 1.9629993, 1.8620741],\n",
       "       [2.0028777, 1.8331099, 1.9771816, 1.9653213, 1.862732 ],\n",
       "       [2.0057302, 1.8334954, 1.979782 , 1.9675845, 1.8635768],\n",
       "       [2.0084476, 1.8338182, 1.9823917, 1.9698155, 1.8644528],\n",
       "       [2.011122 , 1.8341233, 1.9849861, 1.97196  , 1.8653411],\n",
       "       [2.0137916, 1.8344283, 1.9875191, 1.9739649, 1.866211 ],\n",
       "       [2.0163264, 1.8347728, 1.9899503, 1.9759187, 1.8668938],\n",
       "       [2.0187726, 1.8351609, 1.9923347, 1.9778163, 1.8675797],\n",
       "       [2.0210583, 1.835746 , 1.9946864, 1.9797739, 1.8682847],\n",
       "       [2.0233877, 1.8363512, 1.9972311, 1.9817226, 1.8690069],\n",
       "       [2.025881 , 1.8369726, 1.9998063, 1.9835316, 1.869744 ],\n",
       "       [2.0283573, 1.8375529, 2.0023384, 1.9853531, 1.8705577],\n",
       "       [2.0307658, 1.8380964, 2.0046937, 1.9871464, 1.8713694],\n",
       "       [2.0330017, 1.838621 , 2.006934 , 1.9890265, 1.8721683],\n",
       "       [2.0352325, 1.8391522, 2.0090635, 1.9909577, 1.8729359],\n",
       "       [2.0373418, 1.8396939, 2.0112412, 1.9928616, 1.8736931],\n",
       "       [2.0393636, 1.8402182, 2.0133479, 1.9947741, 1.8744435],\n",
       "       [2.0412223, 1.8414967, 2.0154   , 1.9967585, 1.8751417],\n",
       "       [2.0429685, 1.8428477, 2.0174756, 1.9988282, 1.875718 ],\n",
       "       [2.0455348, 1.8441726, 2.0195618, 2.0009842, 1.8762584],\n",
       "       [2.0481286, 1.8453748, 2.0215757, 2.0031664, 1.8769335],\n",
       "       [2.0507061, 1.8468825, 2.023501 , 2.005332 , 1.8776853],\n",
       "       [2.0532231, 1.8484998, 2.0254061, 2.007461 , 1.8784852],\n",
       "       [2.0559728, 1.85012  , 2.0273366, 2.0093973, 1.8792696],\n",
       "       [2.0587728, 1.8517513, 2.0292492, 2.0111759, 1.8800168],\n",
       "       [2.0618277, 1.8534615, 2.0310998, 2.0128908, 1.8807662],\n",
       "       [2.0648198, 1.8553685, 2.0326445, 2.0145614, 1.8816993],\n",
       "       [2.067603 , 1.8576689, 2.0341036, 2.016106 , 1.8827304],\n",
       "       [2.0704374, 1.8602053, 2.0357642, 2.0176702, 1.883686 ]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 335,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lr = LassoCV(eps=1e-2)\n",
    "lr.fit(reg_train.numpy(), y_train.numpy())\n",
    "y_pred = lr.predict(reg_test.numpy())\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "\n",
    "y_mean = np.zeros(y_test.shape) + y_train.numpy().mean()\n",
    "mean_mse = mean_squared_error(y_test.numpy(), y_mean)\n",
    "print(f'Linear regression MSE: {mse:.4f}, mean baseline mse: {mean_mse:.4f}')\n",
    "\n",
    "lr.mse_path_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Linear regression MSE: 1.8263, mean baseline mse: 1.9978\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LassoCV\n",
    "\n",
    "lr = LassoCV(eps=1e-2)\n",
    "lr.fit(X_train.numpy(), y_train.numpy())\n",
    "y_pred = lr.predict(X_test.numpy())\n",
    "mse = mean_squared_error(y_test.numpy(), y_pred)\n",
    "\n",
    "y_mean = np.zeros(y_test.shape) + y_train.numpy().mean()\n",
    "mean_mse = mean_squared_error(y_test.numpy(), y_mean)\n",
    "print(f'Linear regression MSE: {mse:.4f}, mean baseline mse: {mean_mse:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
