{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import model\n",
    "from data_utils.loader import Loader\n",
    "from model.deconfounder import Deconfounder\n",
    "from pyro.optim import Adam\n",
    "\n",
    "import torch\n",
    "import pyro\n",
    "from pyro.distributions import Normal, Bernoulli\n",
    "import numpy as np\n",
    "from scipy import stats, sparse\n",
    "from numpy import random as npr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/ohe_movies.csv\"\n",
    "loader = Loader(data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3181, 129]) torch.Size([3181])\n"
     ]
    }
   ],
   "source": [
    "X, y = torch.tensor(loader.X), torch.tensor(loader.y)\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_datapoints, data_dim = X.shape\n",
    "\n",
    "holdout_portion = 0.1\n",
    "n_holdout = int(holdout_portion * num_datapoints * data_dim)\n",
    "\n",
    "holdout_row = np.random.randint(num_datapoints, size=n_holdout)\n",
    "holdout_col = np.random.randint(data_dim, size=n_holdout)\n",
    "holdout_mask = (sparse.coo_matrix((np.ones(n_holdout), \\\n",
    "                            (holdout_row, holdout_col)), \\\n",
    "                            shape = X.shape)).toarray()\n",
    "\n",
    "holdout_subjects = np.unique(holdout_row)\n",
    "holdout_mask = np.minimum(1, holdout_mask)\n",
    "\n",
    "x_train = np.multiply(1-holdout_mask, X)\n",
    "x_val = np.multiply(holdout_mask, X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# linear conf\n",
    "step1_opt = Adam({\"lr\": 0.0005})\n",
    "step2_opt = Adam({\"lr\": 0.005})\n",
    "# seed def = 3493204\n",
    "deconfounder = Deconfounder(step1_opt, step2_opt, \n",
    "                            seed=5323,\n",
    "                            step1_iters=500, step2_iters=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Training Z marginal and W parameter marginal...\n",
      "[iteration 0001] loss: 378.1893\n",
      "[iteration 0101] loss: 357.4209\n",
      "[iteration 0201] loss: 336.0054\n",
      "[iteration 0301] loss: 325.3372\n",
      "[iteration 0401] loss: 312.4947\n",
      "Updating value of hypermeterqz_mean\n",
      "Updating value of hypermeterqz_stddv\n",
      "Updating value of hypermeterqw_mean\n",
      "Updating value of hypermeterqw_stddv\n",
      "Training Bayesian regression parameters...\n",
      "[iteration 0001] loss: 484.5499\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python3.8/site-packages/pyro/infer/svi.py:51: FutureWarning: The `num_samples` argument to SVI is deprecated and will be removed in a future release. Use `pyro.infer.Predictive` class to draw samples from the posterior.\n",
      "  warnings.warn('The `num_samples` argument to SVI is deprecated and will be removed in '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[iteration 0101] loss: 385.2076\n",
      "[iteration 0201] loss: 362.6943\n",
      "[iteration 0301] loss: 334.9950\n",
      "[iteration 0401] loss: 328.3191\n",
      "Updating value of hypermeter: w_loc\n",
      "Updating value of hypermeter: w_scale\n",
      "Updating value of hypermeter: b_loc\n",
      "Updating value of hypermeter: b_scale\n",
      "Updating value of hypermeter: sigma_loc\n",
      "Updating value of hypermeter: sigma_scale\n",
      "Training complete.\n"
     ]
    }
   ],
   "source": [
    "step1_params, step2_params = deconfounder.train(X, y, mask=torch.Tensor(1-holdout_mask))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3181, 50])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1_params['z_mean0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3181, 50])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "step1_params['z_mean0'].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_rep = 100 # number of replicated datasets we generate\n",
    "holdout_gen = np.zeros((n_rep,*(x_train.shape)))\n",
    "\n",
    "for i in range(n_rep):\n",
    "    w_sample = pyro.sample('w', Normal(step1_params['w_mean0'], step1_params['w_std0']))\n",
    "    z_sample = pyro.sample('z', Normal(step1_params['z_mean0'], step1_params['z_std0']))\n",
    "    linear_exp = torch.matmul(z_sample, w_sample)\n",
    "    x_generated = pyro.sample(\"x\", Bernoulli(logits = linear_exp))\n",
    "\n",
    "    # look only at the heldout entries\n",
    "    holdout_gen[i] = np.multiply(x_generated, holdout_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "4\n",
      "5\n",
      "6\n",
      "7\n",
      "8\n",
      "9\n",
      "10\n",
      "11\n",
      "12\n",
      "13\n",
      "14\n",
      "15\n",
      "16\n",
      "17\n",
      "18\n",
      "19\n",
      "20\n",
      "21\n",
      "22\n",
      "23\n",
      "24\n",
      "25\n",
      "26\n",
      "27\n",
      "28\n",
      "29\n",
      "30\n",
      "31\n",
      "32\n",
      "33\n",
      "34\n",
      "35\n",
      "36\n",
      "37\n",
      "38\n",
      "39\n",
      "40\n",
      "41\n",
      "42\n",
      "43\n",
      "44\n",
      "45\n",
      "46\n",
      "47\n",
      "48\n",
      "49\n",
      "50\n",
      "51\n",
      "52\n",
      "53\n",
      "54\n",
      "55\n",
      "56\n",
      "57\n",
      "58\n",
      "59\n",
      "60\n",
      "61\n",
      "62\n",
      "63\n",
      "64\n",
      "65\n",
      "66\n",
      "67\n",
      "68\n",
      "69\n",
      "70\n",
      "71\n",
      "72\n",
      "73\n",
      "74\n",
      "75\n",
      "76\n",
      "77\n",
      "78\n",
      "79\n",
      "80\n",
      "81\n",
      "82\n",
      "83\n",
      "84\n",
      "85\n",
      "86\n",
      "87\n",
      "88\n",
      "89\n",
      "90\n",
      "91\n",
      "92\n",
      "93\n",
      "94\n",
      "95\n",
      "96\n",
      "97\n",
      "98\n",
      "99\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_eval = 100 # we draw samples from the inferred Z and W\n",
    "obs_ll = []\n",
    "rep_ll = []\n",
    "for j in tqdm(range(n_eval)):\n",
    "    w_sample = pyro.sample('w', Normal(step1_params['w_mean0'], step1_params['w_std0']))\n",
    "    z_sample = pyro.sample('z', Normal(step1_params['z_mean0'], step1_params['z_std0']))\n",
    "    linear_exp = torch.matmul(z_sample, w_sample)\n",
    "    x_generated = np.multiply(pyro.sample(\"x\", Bernoulli(logits = linear_exp)), holdout_mask)\n",
    "    obs_ll.append(np.mean(stats.norm(x_generated).logpdf(x_val), axis=1))\n",
    "    rep_ll.append(np.mean(stats.norm(x_generated).logpdf(holdout_gen), axis=2))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predictive check p-values 0.49686262181703866\n"
     ]
    }
   ],
   "source": [
    "obs_ll_per_zi, rep_ll_per_zi = np.mean(np.array(obs_ll), axis=0), np.mean(np.array(rep_ll), axis=0)\n",
    "\n",
    "pvals = np.array([np.mean(rep_ll_per_zi[:,i] < obs_ll_per_zi[i]) for i in range(num_datapoints)])\n",
    "holdout_subjects = np.unique(holdout_row)\n",
    "overall_pval = np.mean(pvals[holdout_subjects])\n",
    "print(\"Predictive check p-values\", overall_pval)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
